{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised learning algorithms\n",
    "\n",
    "In this document I am going to build an easy practice dataset, and practice classification using different supervised learning algorithms.\n",
    "\n",
    "Things that I want to implement here:\n",
    "- build easy dataset myself -- Check :)\n",
    "- use sklearn to split train and test data (60, 20, 20) -- Check :)\n",
    "- use the k-fold cross validation tactic to verify the statistical robustness of my algorithm's performance\n",
    "- test perfromance\n",
    "\n",
    "- implement k-nearest neighbour classification -- Check :)\n",
    "- implement a decision tree\n",
    "- implement a neural network\n",
    "- implement a bayes classifier\n",
    "\n",
    "Well, let's get started. Wish me luck and endurance! :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build mock dataset\n",
    "\n",
    "feature1 = [1, 2,3, 2, 3, 3, 3, 3,  4, 5, 5, 6, 6, 6, 6, 7, 8, 8,8, 8,8, 8, 9, 9, 9]\n",
    "feature2 = [7, 2,5, 3, 1, 1, 4, 3,  3, 2, 6, 2, 5, 7, 4, 8, 5, 1, 4, 9,6, 7, 8, 7, 9]\n",
    "outcome = [\"sunflower\", \"tulip\",\"tulip\",\"tulip\",\"tulip\",\"sunflower\", \"sunflower\",\"tulip\",\"tulip\",\"sunflower\" ,\"tulip\", \"sunflower\",\"tulip\", \"sunflower\",\"cactus\", \"sunflower\", \"cactus\",\"cactus\",\"sunflower\", \"sunflower\", \"cactus\",\"sunflower\",\"cactus\", \"cactus\",\"cactus\"]\n",
    "\n",
    "mock_data = {}\n",
    "\n",
    "mock_data[\"feature1\"] = feature1\n",
    "mock_data[\"feature2\"] = feature2\n",
    "mock_data[\"outcome\"] = outcome\n",
    "\n",
    "\n",
    "mock_data = pd.DataFrame(mock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data into input features (y) and output criterion (X)\n",
    "\n",
    "y = mock_data.loc[:, mock_data.columns != 'outcome']\n",
    "X = mock_data.loc[:,'outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get seperate train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "\n",
    "# split the test data again for final test vs cross validation tests\n",
    "X_test_for_cross_validation, X_final_test, y_test_for_cross_validation, y_final_test = train_test_split(X_test, y_test, test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest neighbour algorithm\n",
    "\n",
    "input needed:\n",
    "- k (how many nearest neighbours) (either given or optimized within algorithm)\n",
    "- old data training set including categories, new data point without category\n",
    "\n",
    "pseudo-code:\n",
    "\n",
    "    def KNearestNeighbourClassifier(train_data, k, test_data):\n",
    "        for each row in train_data:\n",
    "            calc distance from test_data\n",
    "        get min distance\n",
    "        get categories of tain_data that has min distance\n",
    "        get most numerous category of tain_data that has min distance\n",
    "        return(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data is need with features and outcomes:\n",
    "training_data = y_train.join(X_train)\n",
    "training_data\n",
    "test_data = [12,10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tulip\n",
      "sunflower\n"
     ]
    }
   ],
   "source": [
    "# define class\n",
    "class KNearestNeighbourClassifier:\n",
    "\n",
    "    # constructor\n",
    "    def __init__(self, trainDataDF, k = None, testDataDF = None, trueLabelsTestDataDF = None):\n",
    "        self.trainDataDF = trainDataDF\n",
    "        self.testDataDF = testDataDF\n",
    "        self.trueLabelsTestDataDF = trueLabelsTestDataDF\n",
    "        if k==None:\n",
    "            self.k = self.optimizeK()\n",
    "        else:\n",
    "            self.k = k\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"K Nearest Neighbour Classifier Object\"\n",
    "\n",
    "\n",
    "    # define methods\n",
    "\n",
    "    def optimizeK(self):\n",
    "        accuracyForEachK = []\n",
    "        # loop over all possible k\n",
    "        for potentialK in range(1,len(self.trainDataDF)+1):\n",
    "            listOfPredictions = []\n",
    "            # in each k loop, loop over all test data cases, build a list with the predictions for each case, given the k\n",
    "            for index, row in self.testDataDF.iterrows():\n",
    "                functionInput = [row[0], row[1]]\n",
    "                category = self.predict(functionInput, potentialK)\n",
    "                listOfPredictions.append(category)\n",
    "            # calculate the accuracy for each k, save it in a list\n",
    "            comparison = self.trueLabelsTestDataDF == listOfPredictions\n",
    "            correctClassifiedCounter= 0\n",
    "            for item in comparison:\n",
    "                if item == True:\n",
    "                    correctClassifiedCounter+=1\n",
    "            accuracyForEachK.append(correctClassifiedCounter/len(listOfPredictions))\n",
    "        # choose the key that optimzes the accuracy\n",
    "        optimizedK = accuracyForEachK.index(max(accuracyForEachK))+1\n",
    "                \n",
    "        return(optimizedK)\n",
    "    \n",
    "\n",
    "    def predict(self, testDataList, k = None):\n",
    "        \"\"\"\n",
    "        function that returns the predicted/classified category for a new datapoint using old datapoints that have categories, using k-NN logic.\n",
    "\n",
    "        Parameters\n",
    "        ---------------\n",
    "        trainDataDF: pd. Data frame with two input features and one output category\n",
    "        k: number of closest datapoint that the category should be dirived from\n",
    "        testDataList: list with two integers (that represent the feature 1 and 2 attribute)\n",
    "\n",
    "        Returns\n",
    "        ---------------\n",
    "        category: string with predicted category\n",
    "            \n",
    "        \"\"\"\n",
    "    \n",
    "        # initiate dict and two list to hold information, which we will need to save for further processes\n",
    "        dictToSaveDistances = {}\n",
    "        kMinIndexes = []\n",
    "        categoriesOfMinDistanceEntries = []\n",
    "\n",
    "        # calculate distance (helper function) from every old data point to new datapoint and save distances as values in dictionary where their index is the key (to identify later)\n",
    "        for index, row in self.trainDataDF.iterrows():\n",
    "            dictToSaveDistances[index] = self.__getEuclideanDistance(row[0], row[1], testDataList[0], testDataList[1])\n",
    "\n",
    "        # Either use the k passed to this function, or the one prepared when instantiating a classifier\n",
    "        chosenK = [self.k if k == None else k][0]\n",
    "\n",
    "        # identify k min distances and save indexes of those in a list \n",
    "        for i in range(chosenK):\n",
    "            MinKey = min(dictToSaveDistances, key = dictToSaveDistances.get)\n",
    "            kMinIndexes.append(MinKey)\n",
    "            del dictToSaveDistances[MinKey]\n",
    "\n",
    "        # for each of the indexes of k minimal distances, retrieve category and save in list\n",
    "        for i in kMinIndexes:\n",
    "            categoriesOfMinDistanceEntries.append(self.trainDataDF[\"outcome\"].loc[i])\n",
    "        \n",
    "        # retrieve most common category from k min distance cases, and return it as predicted category\n",
    "        category = max(categoriesOfMinDistanceEntries,key=categoriesOfMinDistanceEntries.count)\n",
    "        return(category)\n",
    "    \n",
    "    # helper function: calculate euclidean distance with 2 coordinates of the train and two coordinates of the test data \n",
    "    ### todo: can I generalize the function to take in any input coordinate length?!\n",
    "    @staticmethod\n",
    "    def __getEuclideanDistance(trainData1Coordinate, trainData2Coordinate, testData1Coordinate, testData2Coordinate):\n",
    "        distance = math.sqrt((trainData1Coordinate-testData1Coordinate)**2+(trainData2Coordinate-testData2Coordinate)**2)\n",
    "        return(distance)\n",
    "\n",
    "\n",
    "\n",
    "# test\n",
    "model1 = KNearestNeighbourClassifier(trainDataDF = training_data, testDataDF = y_test_for_cross_validation, trueLabelsTestDataDF = X_test_for_cross_validation)\n",
    "model2 = KNearestNeighbourClassifier(trainDataDF = training_data, k=15)\n",
    "\n",
    "test_data_1 = [0, 0]\n",
    "test_data_2 = [12,10]\n",
    "print(model1.predict(test_data_1))\n",
    "print(model2.predict(test_data_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Algorithm\n",
    "\n",
    "input needed:\n",
    "- best: categorical data\n",
    "- old data training set including categories, new data point without category\n",
    "\n",
    "pseudo-code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build mock dataset\n",
    "\n",
    "categoricalFeature1 = [\"book\", \"book\",\"movie\", \"movie\",\"movie\",\"movie\",\"movie\",\"movie\",\"book\",\"movie\",\"book\",\"book\",\"movie\",\"book\",\"book\",\"book\",\"movie\",\"sleep\",\"book\",\"movie\",\"sleep\",\"book\",\"sleep\",\"sleep\",\"book\",]\n",
    "categoricalFeature2 = [\"male\", \"female\", \"female\", \"female\", \"male\",\"male\", \"female\", \"female\", \"male\", \"female\",\"male\", \"female\",\"female\",  \"male\", \"female\",  \"female\", \"male\", \"female\", \"female\", \"male\", \"female\", \"male\", \"female\", \"female\", \"female\"]\n",
    "outcome = [\"sunflower\", \"tulip\",\"tulip\",\"tulip\",\"tulip\",\"sunflower\", \"sunflower\",\"tulip\",\"tulip\",\"sunflower\" ,\"tulip\", \"sunflower\",\"tulip\", \"sunflower\",\"cactus\", \"sunflower\", \"cactus\",\"cactus\",\"sunflower\", \"sunflower\", \"cactus\",\"sunflower\",\"cactus\", \"cactus\",\"cactus\"]\n",
    "\n",
    "mock_data = {}\n",
    "\n",
    "mock_data[\"categoricalFeature1\"] = categoricalFeature1\n",
    "mock_data[\"categoricalFeature2\"] = categoricalFeature2\n",
    "mock_data[\"outcome\"] = outcome\n",
    "\n",
    "\n",
    "mock_data = pd.DataFrame(mock_data)\n",
    "\n",
    "\n",
    "# divide data into input features (y) and output criterion (X)\n",
    "\n",
    "y = mock_data.loc[:, mock_data.columns != 'outcome']\n",
    "X = mock_data.loc[:,'outcome']\n",
    "\n",
    "# get seperate train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "\n",
    "# split the test data again for final test vs cross validation tests\n",
    "X_test_for_cross_validation, X_final_test, y_test_for_cross_validation, y_final_test = train_test_split(X_test, y_test, test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categoricalFeature1</th>\n",
       "      <th>categoricalFeature2</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>book</td>\n",
       "      <td>female</td>\n",
       "      <td>cactus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>movie</td>\n",
       "      <td>female</td>\n",
       "      <td>tulip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sleep</td>\n",
       "      <td>female</td>\n",
       "      <td>cactus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>book</td>\n",
       "      <td>female</td>\n",
       "      <td>cactus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>book</td>\n",
       "      <td>female</td>\n",
       "      <td>sunflower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>movie</td>\n",
       "      <td>female</td>\n",
       "      <td>sunflower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>book</td>\n",
       "      <td>female</td>\n",
       "      <td>sunflower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book</td>\n",
       "      <td>male</td>\n",
       "      <td>sunflower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movie</td>\n",
       "      <td>male</td>\n",
       "      <td>tulip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>book</td>\n",
       "      <td>male</td>\n",
       "      <td>sunflower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>book</td>\n",
       "      <td>male</td>\n",
       "      <td>tulip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>movie</td>\n",
       "      <td>male</td>\n",
       "      <td>cactus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sleep</td>\n",
       "      <td>female</td>\n",
       "      <td>cactus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sleep</td>\n",
       "      <td>female</td>\n",
       "      <td>cactus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sleep</td>\n",
       "      <td>female</td>\n",
       "      <td>cactus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   categoricalFeature1 categoricalFeature2    outcome\n",
       "14                book              female     cactus\n",
       "7                movie              female      tulip\n",
       "23               sleep              female     cactus\n",
       "24                book              female     cactus\n",
       "18                book              female  sunflower\n",
       "6                movie              female  sunflower\n",
       "11                book              female  sunflower\n",
       "0                 book                male  sunflower\n",
       "4                movie                male      tulip\n",
       "21                book                male  sunflower\n",
       "10                book                male      tulip\n",
       "16               movie                male     cactus\n",
       "20               sleep              female     cactus\n",
       "17               sleep              female     cactus\n",
       "22               sleep              female     cactus"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data is need with features and outcomes:\n",
    "training_data = y_train.join(X_train)\n",
    "training_data\n",
    "#test_data = [12,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old programming stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stuff from kNN classifier\n",
    "\n",
    "\n",
    "def EuclideanDistance(int1, int2):\n",
    "    distance = math.sqrt((int1-int2)**2)\n",
    "    return(distance)\n",
    "\n",
    "\n",
    "# helper function: calculate euclidean distance with 2 coordinates of the train and two coordinates of the test data \n",
    "### todo: can I generalize the function to take in any input coordinate length?!\n",
    "def getEuclideanDistance(trainData1Coordinate, trainData2Coordinate, testData1Coordinate, testData2Coordinate):\n",
    "    distance = math.sqrt((trainData1Coordinate-testData1Coordinate)**2+(trainData2Coordinate-testData2Coordinate)**2)\n",
    "    return(distance)\n",
    "\n",
    "\n",
    "def kNearestNeighbourClassifier(trainDataDF, k, testDataList):\n",
    "    \"\"\"\n",
    "        function that returns the predicted/classified category for a new datapoint using old datapoints that have categories, using k-NN logic.\n",
    "\n",
    "        Parameters\n",
    "        ---------------\n",
    "        trainDataDF: pd. Data frame with two input features and one output category\n",
    "        k: number of closest datapoint that the category should be dirived from\n",
    "        testDataList: list with two integers (that represent the feature 1 and 2 attribute)\n",
    "\n",
    "        Returns\n",
    "        ---------------\n",
    "        category: string with predicted category\n",
    "            \n",
    "        \"\"\"\n",
    "    \n",
    "    # initiate dict and two list to hold information, which we will need to save for further processes\n",
    "    dictToSaveDistances = {}\n",
    "    kMinIndexes = []\n",
    "    categoriesOfMinDistanceEntries = []\n",
    "\n",
    "    # calculate distance (helper function) from every old data point to new datapoint and save distances as values in dictionary where their index is the key (to identify later)\n",
    "    for index, row in trainDataDF.iterrows():\n",
    "        dictToSaveDistances[index] = getEuclideanDistance(row[0], row[1], testDataList[0], testDataList[1])\n",
    "\n",
    "    # identify k min distances and save indexes of those in a list \n",
    "    for i in range(k):\n",
    "       MinKey = min(dictToSaveDistances, key = dictToSaveDistances.get)\n",
    "       kMinIndexes.append(MinKey)\n",
    "       del dictToSaveDistances[MinKey]\n",
    "\n",
    "    # for each of the indexes of k minimal distances, retrieve category and save in list\n",
    "    for i in kMinIndexes:\n",
    "       categoriesOfMinDistanceEntries.append(trainDataDF[\"outcome\"].loc[i])\n",
    "    \n",
    "    # retrieve most common category from k min distance cases, and return it as predicted category\n",
    "    category = max(categoriesOfMinDistanceEntries,key=categoriesOfMinDistanceEntries.count)\n",
    "    return(category)\n",
    "\n",
    "\n",
    "# how to determine an optimized k\n",
    "\n",
    "def optimizeK(trainDataDF, testDataDF, trueLabelsTestDataDF):\n",
    "    accuracyForEachK = []\n",
    "    # loop over all possible k\n",
    "    for k in range(1,len(trainDataDF)+1):\n",
    "        listOfPredictions = []\n",
    "        # in each k loop, loop over all test data cases, build a list with the predictions for each case, given the k\n",
    "        for index, row in testDataDF.iterrows():\n",
    "            functionInput = [row[0], row[1]]\n",
    "            category = kNearestNeighbourClassifier(trainDataDF, k, functionInput)\n",
    "            listOfPredictions.append(category)\n",
    "        # calculate the accuracy for each k, save it in a list\n",
    "        comparison = trueLabelsTestDataDF == listOfPredictions\n",
    "        correctClassifiedCounter= 0\n",
    "        for item in comparison:\n",
    "            if item == True:\n",
    "                correctClassifiedCounter+=1\n",
    "        accuracyForEachK.append(correctClassifiedCounter/len(listOfPredictions))\n",
    "    # choose the key that optimzes the accuracy\n",
    "    optimizedK = accuracyForEachK.index(max(accuracyForEachK))+1\n",
    "            \n",
    "    return(optimizedK)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning — 2024/2025 Unsupervised Learning\n",
    "\n",
    "This assignment will demonstrate how a learning algorithm can distinguish between two distributions of points generated with different parameters, using no information on the target values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Generate 2D points using a multivariate Gaussian distribution\n",
    "1. Use the code in Fig. 1 to generate two sets, each with 500 points (reduce this number if necessary to obtain better visualizations or faster training runs),\n",
    "2. Each dataset should have different centers, and sets should have a small overlap.\n",
    "3. Add a column and fill it with 1 (one) for the first dataset and 2 (two) on the second, so that you can keep track of which distribution generated each point.\n",
    "4. Join and shuffle the dataset.\n",
    "5. The plot of the first two columns should be similar to the one presented in Fig. 2.\n",
    "6. Write the dataset to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '−' (U+2212) (1547293368.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    mean = [−3, −3]\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '−' (U+2212)\n"
     ]
    }
   ],
   "source": [
    "# generate points\n",
    "\n",
    "import matplotlib . pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "mean= [3, 3]\n",
    "cov = [[1, 0], [0, 1]]\n",
    "a = np.random.multivariate_normal(mean, cov, 500).T\n",
    "\n",
    "#mean = [−3, −3]\n",
    "cov = [[2, 0], [0, 5]]\n",
    "b = np.random.multivariate_normal(mean, cov, 500).T\n",
    "\n",
    "c = np.concatenate((a, b) , axis = 1) \n",
    "c=c.T\n",
    "np.random. shuffle (c)\n",
    "c=c.T\n",
    "\n",
    "x = c[0] \n",
    "y=c[1]\n",
    "\n",
    "plt.plot(x, y, ’x’) \n",
    "plt.axis( ’equal’) \n",
    "plt .show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement a simple version of K-Means\n",
    "\n",
    "1. Start by choosing two random points in the dataset r1 and r2 and apply the following adaptation rule:\n",
    "\n",
    "    for all x ∈ the dataset do\n",
    "        if x is closer to r1 than to r2 then\n",
    "            r1 ←(1−α)×r1 +α×x\n",
    "        else if x is closer to r2 than to r1 then\n",
    "            r2 ←(1−α)×r2 +α×x end if\n",
    "    end for\n",
    "\n",
    "2. Repeat for 10 times a passage through all the elements of the dataset (i.e. 10 epochs) with α = 10E − 5 and save:\n",
    "    (i) the consecutive values of r1 and r2 for the first passage; \n",
    "    (ii) the values of r1 and r2 at the end of each passage.\n",
    "\n",
    "3. Plot (i) and (ii) upon the dataset plot in different graphs. Change the value of α and the number of epochs to see the evolution of the representatives clearly. What do you conclude about the evolution of the two points in the different situations? Is there any relation between the final values of the representatives (r1 and r2) and the parameters used to generate the dataset?\n",
    "\n",
    "4. Instead of changing the value of the representatives for each example, accumulate the values of the difference (x − r) and change the value only when all examples have been observed. Accumulate only for the closest representative in each iteration.\n",
    "for all x do\n",
    "d ← d + (x − r)\n",
    "end for\n",
    "r ← r + (α/n_examples) ∗ d\n",
    "\n",
    "5. Plot the consecutive positions of r1 and r2 and compare with the plot in exercise 1.\n",
    "What do you observe?\n",
    "\n",
    "6. Plot with different colors:\n",
    "• color 1 – points closer to r1 labeled 1; • color 2 – points closer to r1 labeled 2; • color 3 – points closer to r2 labeled 1; • color 4 – points closer to r2 labeled 2.\n",
    "What do you observe?\n",
    "\n",
    "7. Repeat the experiment 30 times and plot the final values of r1 and r2 over the dataset. If necessary amplify the viewed area to see the points’ distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2\n",
    "Implement a simplified version of agglomerative hierarchical clustering, as proposed in the following algorithm.\n",
    "while there are more than two points do Find the closest two points\n",
    "Replace both points by their average\n",
    "end while\n",
    "Test it on sets of points similar to the ones of the last exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3\n",
    "Implement the DBScan algorithm as described in https://www.youtube.com/watch?v=_A9Tq6mGtLI and demonstrate graphically the process with a series of snapshots of the process at key points with adequate descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

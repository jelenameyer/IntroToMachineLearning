{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning — 2024/2025 Supervised Learning\n",
    "\n",
    "In the following exercises the objective is to program algorithms that, given examples and\n",
    "an expected output, learn to mimic the behavior present in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load important packages\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "The “network” in Fig. 1 represents a perceptron with two inputs and an output that can also be described by the following equations:\n",
    "\n",
    "    o=f(s), s=w0 +w1 ·x1 +w2 ·x2 \n",
    "    f(s)=   1, if s>0.5 \n",
    "            0, if s≤0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose one of the binary operations (AND or OR) and build two vectors: one with all the different input combinations of two bit patterns (4 vectors): where 0 stands for FALSE and 1 for TRUE ; and another vector containing the target / desired response, d, for each of the corresponding input vectors, as result of the chosen operation, namely: OR {0, 1, 1, 1} or AND {0, 0, 0, 1}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]]\n",
      "[0 0 0 1]\n",
      "[0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "arrayBitPatterns = np.array(((0,0), (0,1), (1,0), (1,1)))\n",
    "\n",
    "arrayANDSolution = np.array((0,0,0,1))\n",
    "arrayORSolution = np.array((0,0,0,1))\n",
    "print(arrayBitPatterns)\n",
    "print(arrayANDSolution)\n",
    "print(arrayORSolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Initialize w0, w1, and w2 to small random values and, for each input pattern, calculate the corresponding output, storing it in vector o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perceptron(w0, w1, w2, arrayBitPatterns):\n",
    "    listOutputPattern = []\n",
    "    for bitPair in arrayBitPatterns:\n",
    "        x1 = bitPair[0]\n",
    "        x2 = bitPair[1]\n",
    "        s = w0 + w1 * x1 + w2 * x2\n",
    "        if s > 0.5:\n",
    "            listOutputPattern.append(1)\n",
    "        if s <= 0.5:\n",
    "            listOutputPattern.append(0)\n",
    "    return(listOutputPattern)\n",
    "    \n",
    "\n",
    "w0 = 0\n",
    "w1 = 0.4\n",
    "w2 = 0.3\n",
    "\n",
    "\n",
    "o = perceptron(w0, w1, w2, arrayBitPatterns)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w0: 0.1419318846673634, w1: 0.3370138113502479, w2: 0.6436810282066089, output: [0, 1, 0, 1]', 'w0: 0.7468719691678977, w1: 0.4452413203149914, w2: 0.40818714506146714, output: [1, 1, 1, 1]', 'w0: 0.2086276812906791, w1: 0.8631030628514068, w2: 0.941816797093986, output: [0, 1, 1, 1]', 'w0: 0.3276768568522953, w1: 0.847086207845933, w2: 0.7996957558956128, output: [0, 1, 1, 1]', 'w0: 0.3999703958435705, w1: 0.622009934694642, w2: 0.23870285927502055, output: [0, 1, 1, 1]', 'w0: 0.4541200520833779, w1: 0.3061431249596218, w2: 0.4998361244928826, output: [0, 1, 1, 1]', 'w0: 0.6054890026733305, w1: 0.5826002738833612, w2: 0.9728225479956774, output: [1, 1, 1, 1]', 'w0: 0.7736294510165285, w1: 0.6049615372636171, w2: 0.5689196085003138, output: [1, 1, 1, 1]', 'w0: 0.15902042024646723, w1: 0.4772225801053377, w2: 0.45421929973407826, output: [0, 1, 1, 1]', 'w0: 0.4854686415516146, w1: 0.780803967158956, w2: 0.183515398888502, output: [0, 1, 1, 1]']\n",
      "[[0, 1, 0, 1], [1, 1, 1, 1], [0, 1, 1, 1], [0, 1, 1, 1], [0, 1, 1, 1], [0, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [0, 1, 1, 1], [0, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "oUnderstandable = []\n",
    "o = []\n",
    "for i in range(10):\n",
    "    w0 = random.random()\n",
    "    w1 = random.random()\n",
    "    w2 = random.random()\n",
    "\n",
    "    oUnderstandable.append(f\"w0: {w0}, w1: {w1}, w2: {w2}, output: {perceptron(w0, w1, w2, arrayBitPatterns)}\")\n",
    "    o.append(perceptron(w0, w1, w2, arrayBitPatterns))\n",
    "\n",
    "print(oUnderstandable)\n",
    "print(o)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculate the difference / error (e = d − o) between the desired response (d) and the output (o), for each output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, -1,  0,  0],\n",
       "       [-1, -1, -1,  0],\n",
       "       [ 0, -1, -1,  0],\n",
       "       [ 0, -1, -1,  0],\n",
       "       [ 0, -1, -1,  0],\n",
       "       [ 0, -1, -1,  0],\n",
       "       [-1, -1, -1,  0],\n",
       "       [-1, -1, -1,  0],\n",
       "       [ 0, -1, -1,  0],\n",
       "       [ 0, -1, -1,  0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = []\n",
    "d = arrayANDSolution\n",
    "for item in o:\n",
    "    e = d-o\n",
    "    error.append(sum(e))\n",
    "\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Implement a k-NN classifier that is specifically suited for the dataset in https://archive.ics.uci.edu/ml/datasets/iris.\n",
    "Given a dataset containing labelled examples (a training set) and a new example (extracted from the test set), the classifier should calculate the euclidean distance from the new example to all the elements of the training set, choose the k closest elements of the training set and output this example classification as the class of the majority of the k closest training set elements (the k-Nearest Neighbors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Split the dataset randomly in two subsets (70% / 30%). Use the bigger subset as the training set and the smaller as the test set. Run all test examples through the classifier and calculate the number of correct predictions over the total number of examples of the test set. Compare the scores of k-NN classifiers for k = 3, 7, and 11. Repeat 30 times, with different dataset splits, for each value of k. Use a boxplot with whiskers graphic to allow easy comparison.\n",
    "2. Plot the confusion matrix of one of the tests for each value of k.\n",
    "3. Considering the dataset presented in Fig. 3, why should k always be an odd number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width           class\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coloumnNames = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\", \"class\"]\n",
    "\n",
    "data = pd.read_csv(\"data/iris.data\", sep = \",\", names = coloumnNames)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data into input features (y) and output criterion (X)\n",
    "\n",
    "y = data.loc[:, data.columns != 'class']\n",
    "X = data.loc[:,'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get seperate train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "\n",
    "# split the test data again for final test vs cross validation tests\n",
    "X_test_for_cross_validation, X_final_test, y_test_for_cross_validation, y_final_test = train_test_split(X_test, y_test, test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width            class\n",
       "14            5.8          4.0           1.2          0.2      Iris-setosa\n",
       "23            5.1          3.3           1.7          0.5      Iris-setosa\n",
       "7             5.0          3.4           1.5          0.2      Iris-setosa\n",
       "94            5.6          2.7           4.2          1.3  Iris-versicolor\n",
       "47            4.6          3.2           1.4          0.2      Iris-setosa\n",
       "..            ...          ...           ...          ...              ...\n",
       "37            4.9          3.1           1.5          0.1      Iris-setosa\n",
       "144           6.7          3.3           5.7          2.5   Iris-virginica\n",
       "26            5.0          3.4           1.6          0.4      Iris-setosa\n",
       "120           6.9          3.2           5.7          2.3   Iris-virginica\n",
       "66            5.6          3.0           4.5          1.5  Iris-versicolor\n",
       "\n",
       "[105 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data is needed with features and outcomes:\n",
    "training_data = y_train.join(X_train)\n",
    "training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jp/7rxct1gj4xsc_51ldxz05w9w0000gn/T/ipykernel_7834/2586032591.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  functionInput = [row[0], row[1]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (5,) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 99\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m(distance)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# test\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m model1 \u001b[38;5;241m=\u001b[39m KNearestNeighbourClassifier(trainDataDF \u001b[38;5;241m=\u001b[39m training_data, testDataDF \u001b[38;5;241m=\u001b[39m y_test_for_cross_validation, trueLabelsTestDataDF \u001b[38;5;241m=\u001b[39m X_test_for_cross_validation)\n\u001b[1;32m    100\u001b[0m model2 \u001b[38;5;241m=\u001b[39m KNearestNeighbourClassifier(trainDataDF \u001b[38;5;241m=\u001b[39m training_data, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(model1\u001b[38;5;241m.\u001b[39mpredict(y_final_test[\u001b[38;5;241m1\u001b[39m]))\n",
      "Cell \u001b[0;32mIn[28], line 10\u001b[0m, in \u001b[0;36mKNearestNeighbourClassifier.__init__\u001b[0;34m(self, trainDataDF, k, testDataDF, trueLabelsTestDataDF)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrueLabelsTestDataDF \u001b[38;5;241m=\u001b[39m trueLabelsTestDataDF\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizeK()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk \u001b[38;5;241m=\u001b[39m k\n",
      "Cell \u001b[0;32mIn[28], line 28\u001b[0m, in \u001b[0;36mKNearestNeighbourClassifier.optimizeK\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestDataDF\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     27\u001b[0m     functionInput \u001b[38;5;241m=\u001b[39m [row[\u001b[38;5;241m0\u001b[39m], row[\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m---> 28\u001b[0m     category \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(functionInput, potentialK)\n\u001b[1;32m     29\u001b[0m     listOfPredictions\u001b[38;5;241m.\u001b[39mappend(category)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# calculate the accuracy for each k, save it in a list\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[28], line 66\u001b[0m, in \u001b[0;36mKNearestNeighbourClassifier.predict\u001b[0;34m(self, testDataList, k)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# calculate distance (helper function) from every old data point to new datapoint and save distances as values in dictionary where their index is the key (to identify later)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainDataDF\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 66\u001b[0m     dictToSaveDistances[index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__getEuclideanDistance(row, testDataList)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Either use the k passed to this function, or the one prepared when instantiating a classifier\u001b[39;00m\n\u001b[1;32m     69\u001b[0m chosenK \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m k][\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[28], line 92\u001b[0m, in \u001b[0;36mKNearestNeighbourClassifier.__getEuclideanDistance\u001b[0;34m(point1, point2)\u001b[0m\n\u001b[1;32m     89\u001b[0m point1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(point1)\n\u001b[1;32m     90\u001b[0m point2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(point2)\n\u001b[0;32m---> 92\u001b[0m distance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39msum((point1 \u001b[38;5;241m-\u001b[39m point2) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(distance)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (5,) (2,) "
     ]
    }
   ],
   "source": [
    "# define class\n",
    "class KNearestNeighbourClassifier:\n",
    "\n",
    "    # constructor\n",
    "    def __init__(self, trainDataDF, k = None, testDataDF = None, trueLabelsTestDataDF = None):\n",
    "        self.trainDataDF = trainDataDF\n",
    "        self.testDataDF = testDataDF\n",
    "        self.trueLabelsTestDataDF = trueLabelsTestDataDF\n",
    "        if k==None:\n",
    "            self.k = self.optimizeK()\n",
    "        else:\n",
    "            self.k = k\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"K Nearest Neighbour Classifier Object\"\n",
    "\n",
    "\n",
    "    # define methods\n",
    "\n",
    "    def optimizeK(self):\n",
    "        accuracyForEachK = []\n",
    "        # loop over all possible k\n",
    "        for potentialK in range(1,len(self.trainDataDF)+1):\n",
    "            listOfPredictions = []\n",
    "            # in each k loop, loop over all test data cases, build a list with the predictions for each case, given the k\n",
    "            for index, row in self.testDataDF.iterrows():\n",
    "                functionInput = [row[0], row[1]]\n",
    "                category = self.predict(functionInput, potentialK)\n",
    "                listOfPredictions.append(category)\n",
    "            # calculate the accuracy for each k, save it in a list\n",
    "            comparison = self.trueLabelsTestDataDF == listOfPredictions\n",
    "            correctClassifiedCounter= 0\n",
    "            for item in comparison:\n",
    "                if item == True:\n",
    "                    correctClassifiedCounter+=1\n",
    "            accuracyForEachK.append(correctClassifiedCounter/len(listOfPredictions))\n",
    "        # choose the key that optimzes the accuracy\n",
    "        optimizedK = accuracyForEachK.index(max(accuracyForEachK))+1\n",
    "                \n",
    "        return(optimizedK)\n",
    "    \n",
    "\n",
    "    def predict(self, testDataList, k = None):\n",
    "        \"\"\"\n",
    "        function that returns the predicted/classified category for a new datapoint using old datapoints that have categories, using k-NN logic.\n",
    "\n",
    "        Parameters\n",
    "        ---------------\n",
    "        trainDataDF: pd. Data frame with two input features and one output category\n",
    "        k: number of closest datapoint that the category should be dirived from\n",
    "        testDataList: list with two integers (that represent the feature 1 and 2 attribute)\n",
    "\n",
    "        Returns\n",
    "        ---------------\n",
    "        category: string with predicted category\n",
    "            \n",
    "        \"\"\"\n",
    "    \n",
    "        # initiate dict and two list to hold information, which we will need to save for further processes\n",
    "        dictToSaveDistances = {}\n",
    "        kMinIndexes = []\n",
    "        categoriesOfMinDistanceEntries = []\n",
    "\n",
    "        # calculate distance (helper function) from every old data point to new datapoint and save distances as values in dictionary where their index is the key (to identify later)\n",
    "        for index, row in self.trainDataDF.iterrows():\n",
    "            dictToSaveDistances[index] = self.__getEuclideanDistance(row, testDataList)\n",
    "\n",
    "        # Either use the k passed to this function, or the one prepared when instantiating a classifier\n",
    "        chosenK = [self.k if k == None else k][0]\n",
    "\n",
    "        # identify k min distances and save indexes of those in a list \n",
    "        for i in range(chosenK):\n",
    "            MinKey = min(dictToSaveDistances, key = dictToSaveDistances.get)\n",
    "            kMinIndexes.append(MinKey)\n",
    "            del dictToSaveDistances[MinKey]\n",
    "\n",
    "        # for each of the indexes of k minimal distances, retrieve category and save in list\n",
    "        for i in kMinIndexes:\n",
    "            categoriesOfMinDistanceEntries.append(self.trainDataDF[\"outcome\"].loc[i])\n",
    "        \n",
    "        # retrieve most common category from k min distance cases, and return it as predicted category\n",
    "        category = max(categoriesOfMinDistanceEntries,key=categoriesOfMinDistanceEntries.count)\n",
    "        return(category)\n",
    "    \n",
    "    # helper function: calculate euclidean distance with 2 coordinates of the train and two coordinates of the test data \n",
    "    ### todo: can I generalize the function to take in any input coordinate length?!\n",
    "    @staticmethod\n",
    "    def __getEuclideanDistance(point1, point2):\n",
    "        point1 = np.array(point1)\n",
    "        point2 = np.array(point2)\n",
    "\n",
    "        distance = np.sqrt(np.sum((point1 - point2) ** 2))\n",
    "\n",
    "        return(distance)\n",
    "\n",
    "\n",
    "\n",
    "# test\n",
    "model1 = KNearestNeighbourClassifier(trainDataDF = training_data, testDataDF = y_test_for_cross_validation, trueLabelsTestDataDF = X_test_for_cross_validation)\n",
    "model2 = KNearestNeighbourClassifier(trainDataDF = training_data, k=15)\n",
    "\n",
    "\n",
    "print(model1.predict(y_final_test[1]))\n",
    "print(model2.predict(y_final_test[1]))\n",
    "print(X_final_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.48074069840786"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def geted(point1, point2):\n",
    "    point1 = np.array(point1)\n",
    "    point2 = np.array(point2)\n",
    "\n",
    "    distance = np.sqrt(np.sum((point1 - point2) ** 2))\n",
    "\n",
    "    return(distance)\n",
    "\n",
    "geted([1, 1, 1], [5, 2, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ellaalle/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 53, 'name': 'Iris', 'repository_url': 'https://archive.ics.uci.edu/dataset/53/iris', 'data_url': 'https://archive.ics.uci.edu/static/public/53/data.csv', 'abstract': 'A small classic dataset from Fisher, 1936. One of the earliest known datasets used for evaluating classification methods.\\n', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 150, 'num_features': 4, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1936, 'last_updated': 'Tue Sep 12 2023', 'dataset_doi': '10.24432/C56C76', 'creators': ['R. A. Fisher'], 'intro_paper': {'ID': 191, 'type': 'NATIVE', 'title': 'The Iris data set: In search of the source of virginica', 'authors': 'A. Unwin, K. Kleinman', 'venue': 'Significance, 2021', 'year': 2021, 'journal': 'Significance, 2021', 'DOI': '1740-9713.01589', 'URL': 'https://www.semanticscholar.org/paper/4599862ea877863669a6a8e63a3c707a787d5d7e', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'This is one of the earliest datasets used in the literature on classification methods and widely used in statistics and machine learning.  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are not linearly separable from each other.\\n\\nPredicted attribute: class of iris plant.\\n\\nThis is an exceedingly simple domain.\\n\\nThis data differs from the data presented in Fishers article (identified by Steve Chadwick,  spchadwick@espeedaz.net ).  The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features.  ', 'purpose': 'N/A', 'funded_by': None, 'instances_represent': 'Each instance is a plant', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': None, 'citation': None}}\n",
      "           name     role         type demographic  \\\n",
      "0  sepal length  Feature   Continuous        None   \n",
      "1   sepal width  Feature   Continuous        None   \n",
      "2  petal length  Feature   Continuous        None   \n",
      "3   petal width  Feature   Continuous        None   \n",
      "4         class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0                                               None    cm             no  \n",
      "1                                               None    cm             no  \n",
      "2                                               None    cm             no  \n",
      "3                                               None    cm             no  \n",
      "4  class of iris plant: Iris Setosa, Iris Versico...  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "iris = fetch_ucirepo(id=53) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = iris.data.features \n",
    "y = iris.data.targets \n",
    "\n",
    "# variable information \n",
    "print(iris.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ucimlrepo.dotdict.dotdict"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

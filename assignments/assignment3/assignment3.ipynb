{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning — 2023/2024 Reinforcement Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Build the simulation environment. Develop the following functionalities:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) The state-transition function (s′ = f (s, a)), where a state (s) and an action (a) are given as argument, and a new state (the arrival state, s′) is returned, so that: f(1,right) = 2, f(1, down) = 11, f(1, up) = 1, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When tie, than always chose random action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stateTransitionFunction(state, action):\n",
    "    newstate = state\n",
    "    if action == 'right':\n",
    "        newstate += 1\n",
    "    elif action == 'left':\n",
    "        newstate -= 1\n",
    "    elif action == 'up':\n",
    "        newstate -= 10\n",
    "    elif action == 'down':\n",
    "        newstate += 10\n",
    "    \n",
    "    if newstate in range(1, 101):\n",
    "        if not (state % 10 == 1 and action == 'left') and not (state % 10 == 0 and action == 'right'):\n",
    "            state = newstate\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stateTransitionFunction(1, \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) A reward function r(s) that rewards all states with 0 and the goal-state(state100) with 100 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewardFunction(state):\n",
    "    reward = 0\n",
    "    if state == 100:\n",
    "        reward = 100\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return (reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewardFunction(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) A function that randomly chooses an action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomlyChoseAction(state):\n",
    "    possibleActions = [\"up\", \"left\", \"right\", \"down\"]\n",
    "    randomPosition = random.randint(0,3)\n",
    "    randomAction = possibleActions[randomPosition]\n",
    "\n",
    "    return (randomAction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d)  An episode consists in all the movements from the start-point until it reaches the goal, or until it gives-up (because it has reached the maximum number of steps allowed). Define the end of the episode as: the robot reaches the goal-state (the plug, marked with an X, state 100) or the robot performs 1000 actions without reaching the goal. After the end of an episode the robot gets the reward (if it has reached the goal) and is always returned to the initial position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxNumberStepsAllowed = 1000\n",
    "\n",
    "finalState = 100\n",
    "state = 1\n",
    "count = 0\n",
    "while state != finalState and count < 1000:\n",
    "    state = stateTransitionFunction(state, randomlyChoseAction(state))\n",
    "    count +=1\n",
    "\n",
    "count\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

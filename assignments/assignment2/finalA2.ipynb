{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning — 2024/2025 Supervised Learning\n",
    "\n",
    "In the following exercises the objective is to program algorithms that, given examples and\n",
    "an expected output, learn to mimic the behavior present in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose one of the binary operations (AND or OR) and build two vectors: one with all the different input combinations of two bit patterns (4 vectors): where 0 stands for FALSE and 1 for TRUE ; and another vector containing the target / desired response, d, for each of the corresponding input vectors, as result of the chosen operation, namely: OR {0, 1, 1, 1} or AND {0, 0, 0, 1}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Initialize w0, w1, and w2 to small random values and, for each input pattern, calculate the corresponding output, storing it in vector o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculate the difference / error (e = d − o) between the desired response (d) and the output (o), for each output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. For each error in e, add to the update term for w0 (∆w0), w1 (∆w1), and w2 (∆w2) according to:\n",
    "\n",
    "\n",
    "    ∆w0 = ∆w0 + α · e\n",
    "\n",
    "    ∆w1 =∆w1 +α·x1 · e\n",
    "    \n",
    "    ∆w2 =∆w2 +α·x2 · e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Prepare your code to cycle through the whole dataset (in this case, 4 examples) several times doing the above procedure (to train for several \"epochs\").\n",
    "6. After all examples are presented (at the end of each epoch), update w0, w1 and w2. so that in the next iteration the error will decrease. Repeat for 20 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Plot the value of the error at the end of each epoch, how does it behave?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Plot the value of each weight at the end of each training epoch. Are the values converging? if so, do they converge to similar values in different runs (with different random intializations)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) What is the effect of increasing/decreasing the α parameter? Can you tell (approximately) what is the \"best\" value for α?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) How many epochs (iterations through the whole set) did it take to get all examples right? (i.e. ∀i : di = oi). Repeat the experiment 30 times with different random values for the initial weights and present the average and standard deviation of the number of epochs it took to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Generate 2D points using a multivariate Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Use the dataset generated in the previous task as the training set for the same perceptron and train it to partition the two datasets (adjust number of epochs if necessary). Notice that the same program learned two different tasks depending on the dataset used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Print/Plot the confusion matrix for the above test. Can you relate each of the numbers in the confusion matrix to the points of a given color on the previously generated figure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Print the metrics (accuracy, precision, recall, and F1) for all the tests: metrics should be an average for 30 tests with the same parameters but different initial weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Implement a k-NN classifier that is specifically suited for the dataset in https://archive.ics.uci.edu/ml/datasets/iris.\n",
    "Given a dataset containing labelled examples (a training set) and a new example (extracted from the test set), the classifier should calculate the euclidean distance from the new example to all the elements of the training set, choose the k closest elements of the training set and output this example classification as the class of the majority of the k closest training set elements (the k-Nearest Neighbors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Split the dataset randomly in two subsets (70% / 30%). Use the bigger subset as the training set and the smaller as the test set. Run all test examples through the classifier and calculate the number of correct predictions over the total number of examples of the test set. Compare the scores of k-NN classifiers for k = 3, 7, and 11. Repeat 30 times, with different dataset splits, for each value of k. Use a boxplot with whiskers graphic to allow easy comparison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Plot the confusion matrix of one of the tests for each value of k.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Considering the dataset presented in Fig. 3, why should k always be an odd number?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Using the dataset from the previous exercise, implement a Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Transform by discretizing all columns’ values into categories with three possible values (low / medium / high). Use a sensible partition for each column. As in the previous exercise, split the dataset randomly in two subsets (70% / 30%). Repeat the process of the previous exercise to obtain evaluation metrics and an example of a confusion matrix (this time, there is no parameter to vary, so only one cycle of 30 repetitions with different dataset partitions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How does this classifier compare to the k-NN classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Use the dataset from the previous exercise, with the categorized values (high, medium, low). Use Iris-setosa as your target value (p+ are the examples classified as Iris-setosa and p− the remaining ones) and create 3 new datasets by putting in each the examples that have the same values in the first column, i.e. Low DataSet has all elements that have the value low in the first column, Medium Dataset, has all the examples that have medium value in the dataset and High Dataset has all elements that have high value in the first column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculate the entropy of the 4 datasets (the complete dataset, and the three subsets).\n",
    "Calculate the gain of the split of S by feature a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What is the value of gain(S, a) for the above split? What does it mean in terms of your ability to classify the elements of S before and after the split?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Do the same for all features of your dataset. Which is the feature with greatest gain? How can you improve your chances of guessing a random examples’ class using this information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Explain how to build a decision tree with this information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
